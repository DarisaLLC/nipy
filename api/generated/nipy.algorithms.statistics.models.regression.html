
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>Neuroimaging in Python &#8212; NIPY Documentation</title>
    <link rel="stylesheet" href="../../_static/nipy.css" type="text/css" />
    <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../../',
        VERSION:     '0.5.0.dev',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../../_static/jquery.js"></script>
    <script type="text/javascript" src="../../_static/underscore.js"></script>
    <script type="text/javascript" src="../../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="algorithms.statistics.models.setupscons" href="nipy.algorithms.statistics.models.setupscons.html" />
    <link rel="prev" title="algorithms.statistics.models.nlsmodel" href="nipy.algorithms.statistics.models.nlsmodel.html" />
  <meta name="keywords" content="nipy, neuroimaging, python, neuroscience, time
				 series">

  </head>
  <body>
<div style="background-color: white; text-align: left; padding: 10px 10px 15px 15px">
 <a href="../../index.html">
  <img src="../../_static/reggie2.png" alt="NIPY logo"  border="0" />
</div>

    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="nipy.algorithms.statistics.models.setupscons.html" title="algorithms.statistics.models.setupscons"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="nipy.algorithms.statistics.models.nlsmodel.html" title="algorithms.statistics.models.nlsmodel"
             accesskey="P">previous</a> |</li>
  <li><a href="../../index.html">NIPY home</a> |&nbsp;</li>

          <li class="nav-item nav-item-1"><a href="../../documentation.html" >NIPY documentation</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../index.html" accesskey="U">API</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">

  
<h4> Site Navigation </h4>
  <ul>
    <li><a href="../../documentation.html">Documentation</a></li>
    <li><a href="../../devel/index.html">Development</a></li>
  </ul>

<h4> NIPY Community </h4>
  <ul class="simple">
    <li><a class="reference external"
	href="http://nipy.org/">Community Home</a></li>
    <li><a class="reference external"
	href="http://nipy.org/project-directory">NIPY Projects</a></li>
    <li><a class="reference external"
	href="https://mail.python.org/mailman/listinfo/neuroimaging">Mailing List</a></li>
    <li><a class="reference external"
	href="license.html">License</a></li>
  </ul>

<h4> Github repo </h4>
  <ul class="simple">
    <li><a class="reference external"
	href="http://github.com/nipy/nipy/">Nipy Github</a></li>
  </ul>

  <h3><a href="../../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">algorithms.statistics.models.regression</a><ul>
<li><a class="reference internal" href="#module-algorithms-statistics-models-regression">Module: <code class="docutils literal"><span class="pre">algorithms.statistics.models.regression</span></code></a></li>
<li><a class="reference internal" href="#classes">Classes</a><ul>
<li><a class="reference internal" href="#arestimator"><code class="docutils literal"><span class="pre">AREstimator</span></code></a></li>
<li><a class="reference internal" href="#armodel"><code class="docutils literal"><span class="pre">ARModel</span></code></a></li>
<li><a class="reference internal" href="#glsmodel"><code class="docutils literal"><span class="pre">GLSModel</span></code></a></li>
<li><a class="reference internal" href="#olsmodel"><code class="docutils literal"><span class="pre">OLSModel</span></code></a></li>
<li><a class="reference internal" href="#regressionresults"><code class="docutils literal"><span class="pre">RegressionResults</span></code></a></li>
<li><a class="reference internal" href="#wlsmodel"><code class="docutils literal"><span class="pre">WLSModel</span></code></a></li>
</ul>
</li>
<li><a class="reference internal" href="#functions">Functions</a></li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="nipy.algorithms.statistics.models.nlsmodel.html"
                        title="previous chapter">algorithms.statistics.models.nlsmodel</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="nipy.algorithms.statistics.models.setupscons.html"
                        title="next chapter">algorithms.statistics.models.setupscons</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../../_sources/api/generated/nipy.algorithms.statistics.models.regression.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>

<div id="searchbox-ml" style="display: none">
  <h3>Search mailing list archive</h3>
  <script type="text/javascript">
    function mlsearch(curobj)
    {
    curobj.q.value="site:http://mail.python.org/pipermail/neuroimaging/ "+curobj.userquery.value
    }
  </script>
  <form action="http://www.google.com/search" method="get" onSubmit="mlsearch(this)">
    <input name="userquery" size="13" type="text" /> <input type="submit" value="Go" />
    <input name="q" type="hidden" />
  </form>
</div>
  
<div id="searchbox-site" style="display: none">
  <h3>Search this site</h3>
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" size="13" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    </p>
</div>
<script type="text/javascript">$('#searchbox-ml').show(0);</script>
<script type="text/javascript">$('#searchbox-site').show(0);</script>


        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="algorithms-statistics-models-regression">
<h1>algorithms.statistics.models.regression<a class="headerlink" href="#algorithms-statistics-models-regression" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-algorithms-statistics-models-regression">
<h2>Module: <code class="xref py py-mod docutils literal"><span class="pre">algorithms.statistics.models.regression</span></code><a class="headerlink" href="#module-algorithms-statistics-models-regression" title="Permalink to this headline">¶</a></h2>
<p>Inheritance diagram for <code class="docutils literal"><span class="pre">nipy.algorithms.statistics.models.regression</span></code>:</p>
<img src="../../_images/inheritance-9c4b9fcf707ccd140de9305ab2490d2ed9159d4c.png" alt="Inheritance diagram of nipy.algorithms.statistics.models.regression" usemap="#inheritance7534ba070d" class="inheritance"/>
<map id="inheritance7534ba070d" name="inheritance7534ba070d">
<area shape="rect" id="node1" href="nipy.algorithms.statistics.models.model.html#nipy.algorithms.statistics.models.model.LikelihoodModel" target="_top" title="models.model.LikelihoodModel" alt="" coords="238,75,394,93"/>
<area shape="rect" id="node6" href="#nipy.algorithms.statistics.models.regression.OLSModel" target="_top" title="A simple ordinary least squares model." alt="" coords="440,75,585,93"/>
<area shape="rect" id="node2" href="nipy.algorithms.statistics.models.model.html#nipy.algorithms.statistics.models.model.Model" target="_top" title="A (predictive) statistical model." alt="" coords="43,75,152,93"/>
<area shape="rect" id="node3" href="nipy.algorithms.statistics.models.model.html#nipy.algorithms.statistics.models.model.LikelihoodModelResults" target="_top" title="Class to contain results from likelihood models" alt="" coords="4,39,192,58"/>
<area shape="rect" id="node8" href="#nipy.algorithms.statistics.models.regression.RegressionResults" target="_top" title="This class summarizes the fit of a linear regression model." alt="" coords="225,39,406,58"/>
<area shape="rect" id="node4" href="#nipy.algorithms.statistics.models.regression.AREstimator" target="_top" title="A class to estimate AR(p) coefficients from residuals" alt="" coords="20,4,175,22"/>
<area shape="rect" id="node5" href="#nipy.algorithms.statistics.models.regression.ARModel" target="_top" title="A regression model with an AR(p) covariance structure." alt="" coords="621,39,761,58"/>
<area shape="rect" id="node7" href="#nipy.algorithms.statistics.models.regression.GLSModel" target="_top" title="Generalized least squares model with a general covariance structure" alt="" coords="619,75,764,93"/>
<area shape="rect" id="node9" href="#nipy.algorithms.statistics.models.regression.WLSModel" target="_top" title="A regression model with diagonal but non&#45;identity covariance structure." alt="" coords="618,110,764,129"/>
</map>
<span class="target" id="module-nipy.algorithms.statistics.models.regression"></span><p>This module implements some standard regression models: OLS and WLS
models, as well as an AR(p) regression model.</p>
<p>Models are specified with a design matrix and are fit using their
‘fit’ method.</p>
<p>Subclasses that have more complicated covariance matrices
should write over the ‘whiten’ method as the fit method
prewhitens the response by calling ‘whiten’.</p>
<p>General reference for regression models:</p>
<dl class="docutils">
<dt>‘Introduction to Linear Regression Analysis’, Douglas C. Montgomery,</dt>
<dd>Elizabeth A. Peck, G. Geoffrey Vining. Wiley, 2006.</dd>
</dl>
</div>
<div class="section" id="classes">
<h2>Classes<a class="headerlink" href="#classes" title="Permalink to this headline">¶</a></h2>
<div class="section" id="arestimator">
<h3><a class="reference internal" href="#nipy.algorithms.statistics.models.regression.AREstimator" title="nipy.algorithms.statistics.models.regression.AREstimator"><code class="xref py py-class docutils literal"><span class="pre">AREstimator</span></code></a><a class="headerlink" href="#arestimator" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="nipy.algorithms.statistics.models.regression.AREstimator">
<em class="property">class </em><code class="descclassname">nipy.algorithms.statistics.models.regression.</code><code class="descname">AREstimator</code><span class="sig-paren">(</span><em>model</em>, <em>p=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.AREstimator" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal"><span class="pre">object</span></code></p>
<p>A class to estimate AR(p) coefficients from residuals</p>
<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.AREstimator.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>model</em>, <em>p=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.AREstimator.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Bias-correcting AR estimation class</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>model</strong> : <code class="docutils literal"><span class="pre">OSLModel</span></code> instance</p>
<blockquote>
<div><p>A models.regression.OLSmodel instance,
where <cite>model</cite> has attribute <code class="docutils literal"><span class="pre">design</span></code></p>
</div></blockquote>
<p><strong>p</strong> : int, optional</p>
<blockquote class="last">
<div><p>Order of AR(p) noise</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="armodel">
<h3><a class="reference internal" href="#nipy.algorithms.statistics.models.regression.ARModel" title="nipy.algorithms.statistics.models.regression.ARModel"><code class="xref py py-class docutils literal"><span class="pre">ARModel</span></code></a><a class="headerlink" href="#armodel" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="nipy.algorithms.statistics.models.regression.ARModel">
<em class="property">class </em><code class="descclassname">nipy.algorithms.statistics.models.regression.</code><code class="descname">ARModel</code><span class="sig-paren">(</span><em>design</em>, <em>rho</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.ARModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nipy.algorithms.statistics.models.regression.OLSModel" title="nipy.algorithms.statistics.models.regression.OLSModel"><code class="xref py py-class docutils literal"><span class="pre">nipy.algorithms.statistics.models.regression.OLSModel</span></code></a></p>
<p>A regression model with an AR(p) covariance structure.</p>
<p>In terms of a LikelihoodModel, the parameters
are beta, the usual regression parameters,
and sigma, a scalar nuisance parameter that
shows up as multiplier in front of the AR(p) covariance.</p>
<dl class="docutils">
<dt>The linear autoregressive process of order p–AR(p)–is defined as:</dt>
<dd>TODO</dd>
</dl>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nipy.algorithms.statistics.api</span> <span class="k">import</span> <span class="n">Term</span><span class="p">,</span> <span class="n">Formula</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rec</span><span class="o">.</span><span class="n">fromarrays</span><span class="p">(([</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">9</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">)),</span>
<span class="gp">... </span>                         <span class="n">names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">Formula</span><span class="p">([</span><span class="n">Term</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">),</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dmtx</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">design</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">return_float</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">ARModel</span><span class="p">(</span><span class="n">dmtx</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>We go through the <code class="docutils literal"><span class="pre">model.iterative_fit</span></code> procedure long-hand:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">6</span><span class="p">):</span>
<span class="gp">... </span>    <span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
<span class="gp">... </span>    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;AR coefficients:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">rho</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">rho</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">yule_walker</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s2">&quot;Y&quot;</span><span class="p">]</span> <span class="o">-</span> <span class="n">results</span><span class="o">.</span><span class="n">predicted</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">order</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
<span class="gp">... </span>                             <span class="n">df</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">df_resid</span><span class="p">)</span>
<span class="gp">... </span>    <span class="n">model</span> <span class="o">=</span> <span class="n">ARModel</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">design</span><span class="p">,</span> <span class="n">rho</span><span class="p">)</span> 
<span class="gp">...</span>
<span class="go">AR coefficients: [ 0.  0.]</span>
<span class="go">AR coefficients: [-0.61530877 -1.01542645]</span>
<span class="go">AR coefficients: [-0.72660832 -1.06201457]</span>
<span class="go">AR coefficients: [-0.7220361  -1.05365352]</span>
<span class="go">AR coefficients: [-0.72229201 -1.05408193]</span>
<span class="go">AR coefficients: [-0.722278   -1.05405838]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">theta</span> 
<span class="go">array([ 1.59564228, -0.58562172])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">t</span><span class="p">()</span> 
<span class="go">array([ 38.0890515 ,  -3.45429252])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">Tcontrast</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>  
<span class="go">&lt;T contrast: effect=-0.58562172384377043, sd=0.16953449108110835,</span>
<span class="go">t=-3.4542925165805847, df_den=5&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">Fcontrast</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>  
<span class="go">&lt;F contrast: F=4216.810299725842, df_den=5, df_num=2&gt;</span>
</pre></div>
</div>
<p>Reinitialize the model, and do the automated iterative fit</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">rho</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">iterative_fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">],</span> <span class="n">niter</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">rho</span><span class="p">)</span>  
<span class="go">[-0.7220361  -1.05365352]</span>
</pre></div>
</div>
<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.ARModel.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>design</em>, <em>rho</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.ARModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Initialize AR model instance</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>design</strong> : ndarray</p>
<blockquote>
<div><p>2D array with design matrix</p>
</div></blockquote>
<p><strong>rho</strong> : int or array-like</p>
<blockquote class="last">
<div><p>If int, gives order of model, and initializes rho to zeros.  If
ndarray, gives initial estimate of rho. Be careful as <code class="docutils literal"><span class="pre">ARModel(X,</span>
<span class="pre">1)</span> <span class="pre">!=</span> <span class="pre">ARModel(X,</span> <span class="pre">1.0)</span></code>.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.ARModel.iterative_fit">
<code class="descname">iterative_fit</code><span class="sig-paren">(</span><em>Y</em>, <em>niter=3</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.ARModel.iterative_fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Perform an iterative two-stage procedure to estimate AR(p)
parameters and regression coefficients simultaneously.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>Y</strong> : ndarray</p>
<blockquote>
<div><p>data to which to fit model</p>
</div></blockquote>
<p><strong>niter</strong> : optional, int</p>
<blockquote>
<div><p>the number of iterations (default 3)</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">None</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.ARModel.whiten">
<code class="descname">whiten</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.ARModel.whiten" title="Permalink to this definition">¶</a></dt>
<dd><p>Whiten a series of columns according to AR(p) covariance structure</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array-like of shape (n_features)</p>
<blockquote>
<div><p>array to whiten</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>wX</strong> : ndarray</p>
<blockquote class="last">
<div><p>X whitened with order self.order AR</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="glsmodel">
<h3><a class="reference internal" href="#nipy.algorithms.statistics.models.regression.GLSModel" title="nipy.algorithms.statistics.models.regression.GLSModel"><code class="xref py py-class docutils literal"><span class="pre">GLSModel</span></code></a><a class="headerlink" href="#glsmodel" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="nipy.algorithms.statistics.models.regression.GLSModel">
<em class="property">class </em><code class="descclassname">nipy.algorithms.statistics.models.regression.</code><code class="descname">GLSModel</code><span class="sig-paren">(</span><em>design</em>, <em>sigma</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.GLSModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nipy.algorithms.statistics.models.regression.OLSModel" title="nipy.algorithms.statistics.models.regression.OLSModel"><code class="xref py py-class docutils literal"><span class="pre">nipy.algorithms.statistics.models.regression.OLSModel</span></code></a></p>
<p>Generalized least squares model with a general covariance structure</p>
<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.GLSModel.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>design</em>, <em>sigma</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.GLSModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.GLSModel.whiten">
<code class="descname">whiten</code><span class="sig-paren">(</span><em>Y</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.GLSModel.whiten" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</div>
<div class="section" id="olsmodel">
<h3><a class="reference internal" href="#nipy.algorithms.statistics.models.regression.OLSModel" title="nipy.algorithms.statistics.models.regression.OLSModel"><code class="xref py py-class docutils literal"><span class="pre">OLSModel</span></code></a><a class="headerlink" href="#olsmodel" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="nipy.algorithms.statistics.models.regression.OLSModel">
<em class="property">class </em><code class="descclassname">nipy.algorithms.statistics.models.regression.</code><code class="descname">OLSModel</code><span class="sig-paren">(</span><em>design</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.OLSModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="nipy.algorithms.statistics.models.model.html#nipy.algorithms.statistics.models.model.LikelihoodModel" title="nipy.algorithms.statistics.models.model.LikelihoodModel"><code class="xref py py-class docutils literal"><span class="pre">nipy.algorithms.statistics.models.model.LikelihoodModel</span></code></a></p>
<p>A simple ordinary least squares model.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>design</strong> : array-like</p>
<blockquote class="last">
<div><p>This is your design matrix.  Data are assumed to be column ordered with
observations in rows.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nipy.algorithms.statistics.api</span> <span class="k">import</span> <span class="n">Term</span><span class="p">,</span> <span class="n">Formula</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rec</span><span class="o">.</span><span class="n">fromarrays</span><span class="p">(([</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">)),</span>
<span class="gp">... </span>                         <span class="n">names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">Formula</span><span class="p">([</span><span class="n">Term</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">),</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dmtx</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">design</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">return_float</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">OLSModel</span><span class="p">(</span><span class="n">dmtx</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">theta</span>
<span class="go">array([ 0.25      ,  2.14285714])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
<span class="go">array([ 0.98019606,  1.87867287])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">Tcontrast</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>  
<span class="go">&lt;T contrast: effect=2.14285714286, sd=1.14062281591, t=1.87867287326,</span>
<span class="go">df_den=5&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">Fcontrast</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>  
<span class="go">&lt;F contrast: F=19.4607843137, df_den=5, df_num=2&gt;</span>
</pre></div>
</div>
<p class="rubric">Attributes</p>
<table border="1" class="docutils">
<colgroup>
<col width="12%" />
<col width="88%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><strong>design</strong></td>
<td>(ndarray) This is the design, or X, matrix.</td>
</tr>
<tr class="row-even"><td><strong>wdesign</strong></td>
<td>(ndarray) This is the whitened design matrix.  <cite>design</cite> == <cite>wdesign</cite> by default for the OLSModel, though models that inherit from the OLSModel will whiten the design.</td>
</tr>
<tr class="row-odd"><td><strong>calc_beta</strong></td>
<td>(ndarray) This is the Moore-Penrose pseudoinverse of the whitened design matrix.</td>
</tr>
<tr class="row-even"><td><strong>normalized_cov_beta</strong></td>
<td>(ndarray) <code class="docutils literal"><span class="pre">np.dot(calc_beta,</span> <span class="pre">calc_beta.T)</span></code></td>
</tr>
<tr class="row-odd"><td><strong>df_resid</strong></td>
<td>(scalar) Degrees of freedom of the residuals.  Number of observations less the rank of the design.</td>
</tr>
<tr class="row-even"><td><strong>df_model</strong></td>
<td>(scalar) Degrees of freedome of the model.  The rank of the design.</td>
</tr>
</tbody>
</table>
<p class="rubric">Methods</p>
<table border="1" class="docutils">
<colgroup>
<col width="75%" />
<col width="25%" />
</colgroup>
<tbody valign="top">
<tr class="row-odd"><td><strong>model.__init___(design)</strong></td>
<td>&#160;</td>
</tr>
<tr class="row-even"><td><strong>model.logL(b=self.beta, Y)</strong></td>
<td>&#160;</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.OLSModel.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>design</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.OLSModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd><table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>design</strong> : array-like</p>
<blockquote class="last">
<div><p>This is your design matrix.
Data are assumed to be column ordered with
observations in rows.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.OLSModel.fit">
<code class="descname">fit</code><span class="sig-paren">(</span><em>Y</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.OLSModel.fit" title="Permalink to this definition">¶</a></dt>
<dd><p>Fit model to data <cite>Y</cite></p>
<p>Full fit of the model including estimate of covariance matrix,
(whitened) residuals and scale.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>Y</strong> : array-like</p>
<blockquote>
<div><p>The dependent variable for the Least Squares problem.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last"><strong>fit</strong> : RegressionResults</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.OLSModel.has_intercept">
<code class="descname">has_intercept</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.OLSModel.has_intercept" title="Permalink to this definition">¶</a></dt>
<dd><p>Check if column of 1s is in column space of design</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.OLSModel.information">
<code class="descname">information</code><span class="sig-paren">(</span><em>beta</em>, <em>nuisance=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.OLSModel.information" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the information matrix at (beta, Y, nuisance).</p>
<p>See logL for details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>beta</strong> : ndarray</p>
<blockquote>
<div><p>The parameter estimates.  Must be of length df_model.</p>
</div></blockquote>
<p><strong>nuisance</strong> : dict</p>
<blockquote>
<div><p>A dict with key ‘sigma’, which is an estimate of sigma. If None,
defaults to its maximum likelihood estimate (with beta fixed) as
<code class="docutils literal"><span class="pre">sum((Y</span> <span class="pre">-</span> <span class="pre">X*beta)**2)</span> <span class="pre">/</span> <span class="pre">n</span></code> where n=Y.shape[0], X=self.design.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>info</strong> : array</p>
<blockquote class="last">
<div><p>The information matrix, the negative of the inverse of the Hessian
of the of the log-likelihood function evaluated at (theta, Y,
nuisance).</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.OLSModel.initialize">
<code class="descname">initialize</code><span class="sig-paren">(</span><em>design</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.OLSModel.initialize" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.OLSModel.logL">
<code class="descname">logL</code><span class="sig-paren">(</span><em>beta</em>, <em>Y</em>, <em>nuisance=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.OLSModel.logL" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the value of the loglikelihood function at beta.</p>
<p>Given the whitened design matrix, the loglikelihood is evaluated
at the parameter vector, beta, for the dependent variable, Y
and the nuisance parameter, sigma.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>beta</strong> : ndarray</p>
<blockquote>
<div><p>The parameter estimates.  Must be of length df_model.</p>
</div></blockquote>
<p><strong>Y</strong> : ndarray</p>
<blockquote>
<div><p>The dependent variable</p>
</div></blockquote>
<p><strong>nuisance</strong> : dict, optional</p>
<blockquote>
<div><p>A dict with key ‘sigma’, which is an optional estimate of sigma. If
None, defaults to its maximum likelihood estimate (with beta fixed)
as <code class="docutils literal"><span class="pre">sum((Y</span> <span class="pre">-</span> <span class="pre">X*beta)**2)</span> <span class="pre">/</span> <span class="pre">n</span></code>, where n=Y.shape[0], X=self.design.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>loglf</strong> : float</p>
<blockquote class="last">
<div><p>The value of the loglikelihood function.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>The log-Likelihood Function is defined as</p>
<div class="math">
\[\ell(\beta,\sigma,Y)=
-\frac{n}{2}\log(2\pi\sigma^2) - \|Y-X\beta\|^2/(2\sigma^2)\]</div>
<p>The parameter <span class="math">\(\sigma\)</span> above is what is sometimes referred to as a
nuisance parameter. That is, the likelihood is considered as a function
of <span class="math">\(\beta\)</span>, but to evaluate it, a value of <span class="math">\(\sigma\)</span> is
needed.</p>
<p>If <span class="math">\(\sigma\)</span> is not provided, then its maximum likelihood estimate:</p>
<div class="math">
\[\hat{\sigma}(\beta) = \frac{\text{SSE}(\beta)}{n}\]</div>
<p>is plugged in. This likelihood is now a function of only <span class="math">\(\beta\)</span>
and is technically referred to as a profile-likelihood.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="r112" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[R112]</a></td><td><ol class="first last upperalpha simple" start="23">
<li>Green.  “Econometric Analysis,” 5th ed., Pearson, 2003.</li>
</ol>
</td></tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.OLSModel.rank">
<code class="descname">rank</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.OLSModel.rank" title="Permalink to this definition">¶</a></dt>
<dd><p>Compute rank of design matrix</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.OLSModel.score">
<code class="descname">score</code><span class="sig-paren">(</span><em>beta</em>, <em>Y</em>, <em>nuisance=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.OLSModel.score" title="Permalink to this definition">¶</a></dt>
<dd><p>Gradient of the loglikelihood function at (beta, Y, nuisance).</p>
<p>The graient of the loglikelihood function at (beta, Y, nuisance) is the
score function.</p>
<p>See <a class="reference internal" href="#nipy.algorithms.statistics.models.regression.OLSModel.logL" title="nipy.algorithms.statistics.models.regression.OLSModel.logL"><code class="xref py py-meth docutils literal"><span class="pre">logL()</span></code></a> for details.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>beta</strong> : ndarray</p>
<blockquote>
<div><p>The parameter estimates.  Must be of length df_model.</p>
</div></blockquote>
<p><strong>Y</strong> : ndarray</p>
<blockquote>
<div><p>The dependent variable.</p>
</div></blockquote>
<p><strong>nuisance</strong> : dict, optional</p>
<blockquote>
<div><p>A dict with key ‘sigma’, which is an optional estimate of sigma. If
None, defaults to its maximum likelihood estimate (with beta fixed)
as <code class="docutils literal"><span class="pre">sum((Y</span> <span class="pre">-</span> <span class="pre">X*beta)**2)</span> <span class="pre">/</span> <span class="pre">n</span></code>, where n=Y.shape[0], X=self.design.</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first last">The gradient of the loglikelihood function.</p>
</td>
</tr>
</tbody>
</table>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.OLSModel.whiten">
<code class="descname">whiten</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.OLSModel.whiten" title="Permalink to this definition">¶</a></dt>
<dd><p>Whiten design matrix</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> : array</p>
<blockquote>
<div><p>design matrix</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>wX</strong> : array</p>
<blockquote class="last">
<div><p>This matrix is the matrix whose pseudoinverse is ultimately
used in estimating the coefficients. For OLSModel, it is
does nothing. For WLSmodel, ARmodel, it pre-applies
a square root of the covariance matrix to X.</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="regressionresults">
<h3><a class="reference internal" href="#nipy.algorithms.statistics.models.regression.RegressionResults" title="nipy.algorithms.statistics.models.regression.RegressionResults"><code class="xref py py-class docutils literal"><span class="pre">RegressionResults</span></code></a><a class="headerlink" href="#regressionresults" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults">
<em class="property">class </em><code class="descclassname">nipy.algorithms.statistics.models.regression.</code><code class="descname">RegressionResults</code><span class="sig-paren">(</span><em>theta</em>, <em>Y</em>, <em>model</em>, <em>wY</em>, <em>wresid</em>, <em>cov=None</em>, <em>dispersion=1.0</em>, <em>nuisance=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="nipy.algorithms.statistics.models.model.html#nipy.algorithms.statistics.models.model.LikelihoodModelResults" title="nipy.algorithms.statistics.models.model.LikelihoodModelResults"><code class="xref py py-class docutils literal"><span class="pre">nipy.algorithms.statistics.models.model.LikelihoodModelResults</span></code></a></p>
<p>This class summarizes the fit of a linear regression model.</p>
<p>It handles the output of contrasts, estimates of covariance, etc.</p>
<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>theta</em>, <em>Y</em>, <em>model</em>, <em>wY</em>, <em>wresid</em>, <em>cov=None</em>, <em>dispersion=1.0</em>, <em>nuisance=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>See LikelihoodModelResults constructor.</p>
<p>The only difference is that the whitened Y and residual values
are stored for a regression model.</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.F_overall">
<code class="descname">F_overall</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.F_overall" title="Permalink to this definition">¶</a></dt>
<dd><p>Overall goodness of fit F test,
comparing model to a model with just an intercept.
If not an OLS model this is a pseudo-F.</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.MSE">
<code class="descname">MSE</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.MSE" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean square (error)</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.MSR">
<code class="descname">MSR</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.MSR" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean square (regression)</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.MST">
<code class="descname">MST</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.MST" title="Permalink to this definition">¶</a></dt>
<dd><p>Mean square (total)</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.R2">
<code class="descname">R2</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.R2" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the adjusted R^2 value for each row of the response Y.</p>
<p class="rubric">Notes</p>
<p>Changed to the textbook definition of R^2.</p>
<p>See: Davidson and MacKinnon p 74</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.R2_adj">
<code class="descname">R2_adj</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.R2_adj" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the R^2 value for each row of the response Y.</p>
<p class="rubric">Notes</p>
<p>Changed to the textbook definition of R^2.</p>
<p>See: Davidson and MacKinnon p 74</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.SSE">
<code class="descname">SSE</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.SSE" title="Permalink to this definition">¶</a></dt>
<dd><p>Error sum of squares. If not from an OLS model this is “pseudo”-SSE.</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.SSR">
<code class="descname">SSR</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.SSR" title="Permalink to this definition">¶</a></dt>
<dd><p>Regression sum of squares</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.SST">
<code class="descname">SST</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.SST" title="Permalink to this definition">¶</a></dt>
<dd><p>Total sum of squares. If not from an OLS model this is “pseudo”-SST.</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.norm_resid">
<code class="descname">norm_resid</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.norm_resid" title="Permalink to this definition">¶</a></dt>
<dd><p>Residuals, normalized to have unit length.</p>
<p class="rubric">Notes</p>
<p>Is this supposed to return “stanardized residuals,”
residuals standardized
to have mean zero and approximately unit variance?</p>
<p>d_i = e_i / sqrt(MS_E)</p>
<p>Where MS_E = SSE / (n - k)</p>
<dl class="docutils">
<dt>See: Montgomery and Peck 3.2.1 p. 68</dt>
<dd>Davidson and MacKinnon 15.2 p 662</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.predicted">
<code class="descname">predicted</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.predicted" title="Permalink to this definition">¶</a></dt>
<dd><p>Return linear predictor values from a design matrix.</p>
</dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.RegressionResults.resid">
<code class="descname">resid</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.RegressionResults.resid" title="Permalink to this definition">¶</a></dt>
<dd><p>Residuals from the fit.</p>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="wlsmodel">
<h3><a class="reference internal" href="#nipy.algorithms.statistics.models.regression.WLSModel" title="nipy.algorithms.statistics.models.regression.WLSModel"><code class="xref py py-class docutils literal"><span class="pre">WLSModel</span></code></a><a class="headerlink" href="#wlsmodel" title="Permalink to this headline">¶</a></h3>
<dl class="class">
<dt id="nipy.algorithms.statistics.models.regression.WLSModel">
<em class="property">class </em><code class="descclassname">nipy.algorithms.statistics.models.regression.</code><code class="descname">WLSModel</code><span class="sig-paren">(</span><em>design</em>, <em>weights=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.WLSModel" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#nipy.algorithms.statistics.models.regression.OLSModel" title="nipy.algorithms.statistics.models.regression.OLSModel"><code class="xref py py-class docutils literal"><span class="pre">nipy.algorithms.statistics.models.regression.OLSModel</span></code></a></p>
<p>A regression model with diagonal but non-identity covariance structure.</p>
<p>The weights are presumed to be (proportional to the) inverse
of the variance of the observations.</p>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">nipy.algorithms.statistics.api</span> <span class="k">import</span> <span class="n">Term</span><span class="p">,</span> <span class="n">Formula</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">rec</span><span class="o">.</span><span class="n">fromarrays</span><span class="p">(([</span><span class="mi">1</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">],</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">)),</span>
<span class="gp">... </span>                         <span class="n">names</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;Y&#39;</span><span class="p">,</span> <span class="s1">&#39;X&#39;</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span> <span class="o">=</span> <span class="n">Formula</span><span class="p">([</span><span class="n">Term</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">),</span> <span class="mi">1</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">dmtx</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">design</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">return_float</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">WLSModel</span><span class="p">(</span><span class="n">dmtx</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s1">&#39;Y&#39;</span><span class="p">])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">theta</span>
<span class="go">array([ 0.0952381 ,  2.91666667])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span><span class="o">.</span><span class="n">t</span><span class="p">()</span>
<span class="go">array([ 0.35684428,  2.0652652 ])</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">Tcontrast</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">]))</span>  
<span class="go">&lt;T contrast: effect=2.91666666667, sd=1.41224801095, t=2.06526519708,</span>
<span class="go">df_den=5&gt;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="nb">print</span><span class="p">(</span><span class="n">results</span><span class="o">.</span><span class="n">Fcontrast</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="mi">2</span><span class="p">)))</span>  
<span class="go">&lt;F contrast: F=26.9986072423, df_den=5, df_num=2&gt;</span>
</pre></div>
</div>
<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.WLSModel.__init__">
<code class="descname">__init__</code><span class="sig-paren">(</span><em>design</em>, <em>weights=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.WLSModel.__init__" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="nipy.algorithms.statistics.models.regression.WLSModel.whiten">
<code class="descname">whiten</code><span class="sig-paren">(</span><em>X</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.WLSModel.whiten" title="Permalink to this definition">¶</a></dt>
<dd><p>Whitener for WLS model, multiplies by sqrt(self.weights)</p>
</dd></dl>

</dd></dl>

</div>
</div>
<div class="section" id="functions">
<h2>Functions<a class="headerlink" href="#functions" title="Permalink to this headline">¶</a></h2>
<dl class="function">
<dt id="nipy.algorithms.statistics.models.regression.ar_bias_correct">
<code class="descclassname">nipy.algorithms.statistics.models.regression.</code><code class="descname">ar_bias_correct</code><span class="sig-paren">(</span><em>results</em>, <em>order</em>, <em>invM=None</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.ar_bias_correct" title="Permalink to this definition">¶</a></dt>
<dd><p>Apply bias correction in calculating AR(p) coefficients from <cite>results</cite></p>
<p>There is a slight bias in the rho estimates on residuals due to the
correlations induced in the residuals by fitting a linear model.  See
<a class="reference internal" href="#worsley200234" id="id2">[Worsley200234]</a>.</p>
<p>This routine implements the bias correction described in appendix A.1 of
<a class="reference internal" href="#worsley200234" id="id3">[Worsley200234]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>results</strong> : ndarray or results object</p>
<blockquote>
<div><p>If ndarray, assume these are residuals, from a simple model.  If a
results object, with attribute <code class="docutils literal"><span class="pre">resid</span></code>, then use these for the
residuals. See Notes for more detail</p>
</div></blockquote>
<p><strong>order</strong> : int</p>
<blockquote>
<div><p>Order <code class="docutils literal"><span class="pre">p</span></code> of AR(p) model</p>
</div></blockquote>
<p><strong>invM</strong> : None or array</p>
<blockquote>
<div><p>Known bias correcting matrix for covariance.  If None, calculate from
<code class="docutils literal"><span class="pre">results.model</span></code></p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>rho</strong> : array</p>
<blockquote class="last">
<div><p>Bias-corrected AR(p) coefficients</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>If <cite>results</cite> has attributes <code class="docutils literal"><span class="pre">resid</span></code> and <code class="docutils literal"><span class="pre">scale</span></code>, then assume <code class="docutils literal"><span class="pre">scale</span></code>
has come from a fit of a potentially customized model, and we use that for
the sum of squared residuals.  In this case we also need
<code class="docutils literal"><span class="pre">results.df_resid</span></code>.  Otherwise we assume this is a simple Gaussian model,
like OLS, and take the simple sum of squares of the residuals.</p>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="worsley200234" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Worsley200234]</td><td><em>(<a class="fn-backref" href="#id2">1</a>, <a class="fn-backref" href="#id3">2</a>, <a class="fn-backref" href="#id4">3</a>)</em> K.J. Worsley, C.H. Liao, J. Aston, V. Petre, G.H. Duncan,
F. Morales, A.C. Evans (2002) A General Statistical Analysis for fMRI
Data.  Neuroimage 15:1:15</td></tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nipy.algorithms.statistics.models.regression.ar_bias_corrector">
<code class="descclassname">nipy.algorithms.statistics.models.regression.</code><code class="descname">ar_bias_corrector</code><span class="sig-paren">(</span><em>design</em>, <em>calc_beta</em>, <em>order=1</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.ar_bias_corrector" title="Permalink to this definition">¶</a></dt>
<dd><p>Return bias correcting matrix for <cite>design</cite> and AR order <cite>order</cite></p>
<p>There is a slight bias in the rho estimates on residuals due to the
correlations induced in the residuals by fitting a linear model.  See
<a class="reference internal" href="#worsley200256" id="id5">[Worsley200256]</a>.</p>
<p>This routine implements the bias correction described in appendix A.1 of
<a class="reference internal" href="#worsley200256" id="id6">[Worsley200256]</a>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>design</strong> : array</p>
<blockquote>
<div><p>Design matrix</p>
</div></blockquote>
<p><strong>calc_beta</strong> : array</p>
<blockquote>
<div><p>Moore-Penrose pseudoinverse of the (maybe) whitened design matrix.
This is the matrix that, when applied to the (maybe whitened) data,
produces the betas.</p>
</div></blockquote>
<p><strong>order</strong> : int, optional</p>
<blockquote>
<div><p>Order p of AR(p) process</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>invM</strong> : array</p>
<blockquote class="last">
<div><p>Matrix to bias correct estimated covariance matrix
in calculating the AR coefficients</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">References</p>
<table class="docutils citation" frame="void" id="worsley200256" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label">[Worsley200256]</td><td><em>(<a class="fn-backref" href="#id5">1</a>, <a class="fn-backref" href="#id6">2</a>, <a class="fn-backref" href="#id7">3</a>)</em> K.J. Worsley, C.H. Liao, J. Aston, V. Petre, G.H. Duncan,
F. Morales, A.C. Evans (2002) A General Statistical Analysis for fMRI
Data.  Neuroimage 15:1:15</td></tr>
</tbody>
</table>
</dd></dl>

<dl class="function">
<dt id="nipy.algorithms.statistics.models.regression.isestimable">
<code class="descclassname">nipy.algorithms.statistics.models.regression.</code><code class="descname">isestimable</code><span class="sig-paren">(</span><em>C</em>, <em>D</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.isestimable" title="Permalink to this definition">¶</a></dt>
<dd><p>True if (Q, P) contrast <cite>C</cite> is estimable for (N, P) design <cite>D</cite></p>
<p>From an Q x P contrast matrix <cite>C</cite> and an N x P design matrix <cite>D</cite>, checks if
the contrast <cite>C</cite> is estimable by looking at the rank of <code class="docutils literal"><span class="pre">vstack([C,D])</span></code>
and verifying it is the same as the rank of <cite>D</cite>.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>C</strong> : (Q, P) array-like</p>
<blockquote>
<div><p>contrast matrix. If <cite>C</cite> has is 1 dimensional assume shape (1, P)</p>
</div></blockquote>
<p><strong>D: (N, P) array-like</strong></p>
<blockquote>
<div><p>design matrix</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>tf</strong> : bool</p>
<blockquote class="last">
<div><p>True if the contrast <cite>C</cite> is estimable on design <cite>D</cite></p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">D</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
<span class="gp">... </span>              <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]])</span><span class="o">.</span><span class="n">T</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">isestimable</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">D</span><span class="p">)</span>
<span class="go">False</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">isestimable</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">D</span><span class="p">)</span>
<span class="go">True</span>
</pre></div>
</div>
</dd></dl>

<dl class="function">
<dt id="nipy.algorithms.statistics.models.regression.yule_walker">
<code class="descclassname">nipy.algorithms.statistics.models.regression.</code><code class="descname">yule_walker</code><span class="sig-paren">(</span><em>X</em>, <em>order=1</em>, <em>method='unbiased'</em>, <em>df=None</em>, <em>inv=False</em><span class="sig-paren">)</span><a class="headerlink" href="#nipy.algorithms.statistics.models.regression.yule_walker" title="Permalink to this definition">¶</a></dt>
<dd><p>Estimate AR(p) parameters from a sequence X using Yule-Walker equation.</p>
<p>unbiased or maximum-likelihood estimator (mle)</p>
<p>See, for example:</p>
<p><a class="reference external" href="http://en.wikipedia.org/wiki/Autoregressive_moving_average_model">http://en.wikipedia.org/wiki/Autoregressive_moving_average_model</a></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><p class="first"><strong>X</strong> :  ndarray of shape(n)</p>
<p><strong>order</strong> : int, optional</p>
<blockquote>
<div><p>Order of AR process.</p>
</div></blockquote>
<p><strong>method</strong> : str, optional</p>
<blockquote>
<div><p>Method can be “unbiased” or “mle” and this determines denominator in
estimate of autocorrelation function (ACF) at lag k. If “mle”, the
denominator is n=X.shape[0], if “unbiased” the denominator is n-k.</p>
</div></blockquote>
<p><strong>df</strong> : int, optional</p>
<blockquote>
<div><p>Specifies the degrees of freedom. If df is supplied, then it is assumed
the X has df degrees of freedom rather than n.</p>
</div></blockquote>
<p><strong>inv</strong> : bool, optional</p>
<blockquote>
<div><p>Whether to return the inverse of the R matrix (see code)</p>
</div></blockquote>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"><strong>rho</strong> : (<cite>order</cite>,) ndarray</p>
<p><strong>sigma</strong> : int</p>
<blockquote>
<div><p>standard deviation of the residuals after fit</p>
</div></blockquote>
<p><strong>R_inv</strong> : ndarray</p>
<blockquote class="last">
<div><p>If <cite>inv</cite> is True, also return the inverse of the R matrix</p>
</div></blockquote>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>See also
<a class="reference external" href="http://en.wikipedia.org/wiki/AR_model#Calculation_of_the_AR_parameters">http://en.wikipedia.org/wiki/AR_model#Calculation_of_the_AR_parameters</a></p>
</dd></dl>

</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="nipy.algorithms.statistics.models.setupscons.html" title="algorithms.statistics.models.setupscons"
             >next</a> |</li>
        <li class="right" >
          <a href="nipy.algorithms.statistics.models.nlsmodel.html" title="algorithms.statistics.models.nlsmodel"
             >previous</a> |</li>
  <li><a href="../../index.html">NIPY home</a> |&nbsp;</li>

          <li class="nav-item nav-item-1"><a href="../../documentation.html" >NIPY documentation</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="../index.html" >API</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2005-2017, Neuroimaging in Python team.
      Last updated on Jul 08, 2017.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.3.
    </div>
  </body>
</html>